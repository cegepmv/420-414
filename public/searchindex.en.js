var relearn_searchindex = [
  {
    "breadcrumb": "",
    "content": "Qu’est-ce que le Cloud ? En général, quand on pense “Cloud”, on pense surtout aux services de stockage, comme Dropbox, iCloud, Google Drive, ou OneDrive.\nMais le Cloud, c’est bien plus que ça : Il offre des services pour vos besoins informatiques, réseaux, base de données, et même ce que qu’on considère généralement comme le “Cloud” : le stockage de fichiers.\nQuelques-uns de ces outils que nous utilisons tous les jours et dont nous ne savions pas qu’ils faisaient partie du cloud :\nMicrosoft 365 Google Workspace Le “Cloud” est une plate-forme qui permet d’avoir une disponibilité à la demande de ressources informatiques virtuelles pour un usage personnel ou professionnel.\nCes ressources sont utilisées sur la base d’un modèle de paiement à l’utilisation (Pay-as-you-go Model) : vous êtes facturés pour ces services seulement quand vous les utilisez.\nL’utilisation d’une infrastructure ou de services “cloud” signifie que vous ne possédez pas physiquement l’infrastructure. Vous la louez à des fournisseurs de service.\nQuelques exemples de services que vous pouvez utiliser dans le nuage :\nVous pouvez les utiliser pour mettre en place un réseau complet, tester des logiciels ou faire de l’analyse des données… tout ce que vous pouvez imaginer : le nuage n’a pas de limites.\nLes avantages de l’infonuagique Go Global in Minutes : Déployer vos applications dans le monde entier d’un simple clic, lancer des environnements entiers en quelques minutes. Pas de dépenses sur l’infrastructure et la maintenance d’un centre de données (Data Center) : Laisse le temps de se concentrer sur le développement d’applications au lieu de gérer le matériel (vous n’êtes pas propriétaire du centre de données utilisé). Économies d’échelle : Les fournisseurs de services (AWS, GCP ou Azure) possèdent une infrastructure immense, ce qui permet de réduire les couts. Pas besoin de deviner la capacité à l’avance : Gain de temps et d’argent Haute disponibilité (High Availability): Les systèmes à haute disponibilité sont conçus pour fonctionner en continu sans défaillance pendant une longue période. Ces systèmes évitent les pertes de service en réduisant ou en gérant les défaillances. Durabilité : Protection des données à long terme (vos données resteront intactes sans être corrompues). Les fournisseurs de service Les plus populaires (dans l’ordre)\nAWS Microsoft Azure Google Cloud (GCP) D’autres fournisseurs, qui offrent aussi des solution pour créer des infrastructures privées :\nRedhat Dell VMWare OpenStack Emplois dans le monde du Cloud Architecte de solution (Solution Architect) Ingénieur Cloud (Cloud Engineer) : Gestion du nuage Cloud Operations Engineer : Porte d’entrée dans le monde du Cloud (surtout pour quelqu’un qui vient de l’assistance technique) Sales Engineer Ingénieur DevOps (DevOps Engineer) : Responsable de la gestion d’outils et services en utilisant une méthodologie DevOps Support Cloud (Cloud Support) : Rôle généralement basé sur les tickets, en contact direct avec un grand nombre de services dans le nuage.",
    "description": "Qu’est-ce que le Cloud ? En général, quand on pense “Cloud”, on pense surtout aux services de stockage, comme Dropbox, iCloud, Google Drive, ou OneDrive.\nMais le Cloud, c’est bien plus que ça : Il offre des services pour vos besoins informatiques, réseaux, base de données, et même ce que qu’on considère généralement comme le “Cloud” : le stockage de fichiers.\nQuelques-uns de ces outils que nous utilisons tous les jours et dont nous ne savions pas qu’ils faisaient partie du cloud :",
    "tags": [],
    "title": "Introduction",
    "uri": "/420-414/1-introduction/index.html"
  },
  {
    "breadcrumb": "Introduction",
    "content": "Les modèles “as-a-Service” L’expression “as-a-Service” signifie généralement qu’un tiers se charge de vous fournir un service de cloud computing pour que vous puissiez vous concentrer sur des aspects plus importants (développement, relation client etc…).\nInfrastructure sur-site (On-Site) Une infrastructure informatique sur site est la solution qui met le plus de responsabilités entre les mains de l’utilisateur et du responsable. Lorsque l’intégralité du matériel et des logiciels se trouve sur site, vous et votre équipe devez gérer, mettre à jour et, si nécessaire, remplacer chaque composant vous-mêmes.Le cloud computing vous permet d’externaliser la gestion d’un, de plusieurs ou de tous les composants de votre infrastructure en vue de vous faire gagner du temps que vous pourrez consacrer à d’autres tâches.\nPaaS Avec le modèle PaaS, ou Platform-as-a-Service, le fournisseur héberge le matériel et les logiciels sur sa propre infrastructure et met à disposition de l’utilisateur une plateforme via Internet, sous la forme d’une solution intégrée, d’une pile de solutions ou d’un service.\nDestiné aux spécialistes du développement et de la programmation : Vous écrivez le code, créez et gérez vos applications, le tout sans avoir à vous préoccuper des mises à jour logicielles ou de la maintenance du matériel. L’environnement de développement et de déploiement vous est fourni.\nExemples :\nAmazon Elastic Beanstalk (AWS) : service d’orchestration pour le déploiement d’applications qui orchestre divers services AWS Google App Engine (GCP) : Une plate-forme pour le développement et l’hébergement d’applications web dans des centres de données gérés par Google. SaaS En utilisant un produit SaaS (Software as a Service), tout est déjà géré pour vous : Application, Données, Durée d’exécution, Intergiciel, OS, Virtualisation, Serveurs, Stockage et le réseau.\nExemples :\nZoom Dropbox : Service de stockage de fichiers. Slack : Service de communication par messagerie instantanée Mailchimp : Service de marketing par courriel, IaaS Avec l’infrastructure en tant que service, en tant qu’utilisateur, vous êtes responsable de la gestion l’application, les données, le moteur d’exécution, l’intergiciel, et le système d’exploitation, tandis que le fournisseur de services gère la virtualisation, les serveurs, le stockage et le réseau.\nExemples :\nAWS Google Cloud (GCP) Microsoft Azure Modèles de déploiement Le modèle privé (Private Cloud): Pour les organisations qui possèdent un réseau/architecture privé. Les ressources (serveurs, bases de données etc…) sont toutes sur place (on-premise). Un nuage privé ne présente aucun des avantages du nuage discutés plus haut, mais offre plus de sécurité à vos données (elles ne transitent pas par un espace public et ne sont pas partagées avec d’autres organisations) Le modèle public (Public Cloud): L’infrastructure appartient à un fournisseur de service (Cloud Service Provider ou CSP) comme Amazon ou Google ou même Microsoft. Ils fournissent une infrastructure pour des particuliers. Il n’y a aucune responsabilité en matière de matériel (ils fournissent tout le matériel). Le modèle hybride (Hybrid Cloud) : Une combinaison de cloud privé et de cloud public. les données sensibles sont généralement stockées localement et se connectent à l’infrastructure infonuagique publique à l’aide de services comme un VPN.",
    "description": "Les modèles “as-a-Service” L’expression “as-a-Service” signifie généralement qu’un tiers se charge de vous fournir un service de cloud computing pour que vous puissiez vous concentrer sur des aspects plus importants (développement, relation client etc…).\nInfrastructure sur-site (On-Site) Une infrastructure informatique sur site est la solution qui met le plus de responsabilités entre les mains de l’utilisateur et du responsable. Lorsque l’intégralité du matériel et des logiciels se trouve sur site, vous et votre équipe devez gérer, mettre à jour et, si nécessaire, remplacer chaque composant vous-mêmes.",
    "tags": [],
    "title": "Modèles Infonuagiques",
    "uri": "/420-414/1-introduction/1-modeles/index.html"
  },
  {
    "breadcrumb": "Introduction",
    "content": "AWS possède une infrastructure immense, avec des centres de données (data centers) déployés sur les quatre coins du globe. AWS a une façon spécifique de séparer logiquement et physiquement son infrastructure pour permettre une disponibilité et une redondance optimale.\nRégions Une région AWS est une zone géographique.\nVous contrôlez la réplication des données entre les régions. La communication entre les régions s’effecture par le biais de l’infrastructure réseau de AWS. Chaque région AWS assure une redondance et une connectivité complète au réseau AWS.\nUne région se compose de deux zones de disponibilité ou plus.\nZones de disponibilité Chaque région compte plusieurs zones de disponibilité (Availability Zones ou AZs).\nChaque zone de disponibilité est une partition entièrement isolée de l’infrastructure mondiale AWS.\nLes zones de disponibilité consistent en un ou plusieurs centres de données (typiquement 3). Elles sont isolées et conçues pour l’isolation des défaillances : Chaque zone de disponibilité a sa propre source d’alimentation et est physiquement séparée des autres zones de disponibilités. Elles sont interconnectées avec d’autres zones de disponibilité via des réseaux privés à haut débit : permet d’avoir une réplication syncrone et rapide des données (très peu de latence). Vous choisissez vos zones de disponibilité. AWS recommande de répliquer les données et les ressources dans minimum 2 zones de disponibilité pour garantir la résilience de vos services.\nExemple\nLa région Virginie du Nord possède 6 zones de disponibilité : us-east-1a, us-east-1b, us-east-1c, us-east-1d, us-east-1e, us-east-1f Une application s’exécute sur plusieurs zones : 1a, 1b et 1c, mais la zone 1a tombe en panne =\u003e votre application fonctionnera toujours dans les zones 1b et 1c. Centres de données Les centres de données AWS sont conçus pour la sécurité.\nLes centres de données sont l’emplacement où les données sont hébergées et où le traitement des données a lieu.\nChaque centre de données dispose d’une alimentation, d’un réseau et d’une connectivité redondants et est hébergé dans une installation distincte des autres centres de données.\nUn centre de données compte généralement entre 50 000 et 80 000 serveurs physiques !\nAvantages de l’infrastructure AWS Élasticité et mise à l’échelle (scalability) :\nInfrastructure élastique, adaptation dynamique de la capacité Infrastructure évolutive, adaptation à la croissance Tolérance aux pannes :\nFonctionnement continu en cas de panne Redondance intégrée des composants Haute disponibilité :\nHaut niveau de performances opérationnelles Temps d’arrêt réduit (down time) Aucune intervention humaine nécessaire Références Carte interactive de l’infrastructure mondiale de AWS Documentation Infrastructure mondiale AWS",
    "description": "AWS possède une infrastructure immense, avec des centres de données (data centers) déployés sur les quatre coins du globe. AWS a une façon spécifique de séparer logiquement et physiquement son infrastructure pour permettre une disponibilité et une redondance optimale.\nRégions Une région AWS est une zone géographique.\nVous contrôlez la réplication des données entre les régions. La communication entre les régions s’effecture par le biais de l’infrastructure réseau de AWS. Chaque région AWS assure une redondance et une connectivité complète au réseau AWS.",
    "tags": [],
    "title": "Infrastructure AWS",
    "uri": "/420-414/1-introduction/2-infrastructure-aws/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Réseau Infonuagique",
    "uri": "/420-414/2-reseau/index.html"
  },
  {
    "breadcrumb": "Réseau Infonuagique",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Notions",
    "uri": "/420-414/2-reseau/1-notions/index.html"
  },
  {
    "breadcrumb": "Réseau Infonuagique \u003e Notions",
    "content": "Définitions Définition simplifiée :\nUn VPC (Virtual Private Cloud) est une sous-section privée d’AWS que vous contrôlez et dans laquelle vous pouvez placer des ressources AWS (telles que des instances EC2 et des bases de données). Vous avez un contrôle total sur l’accès aux ressources AWS que vous déployez dans votre VPC. Définition d’AWS :\nAmazon Virtual Private Cloud (VPC) permet de mettre en service une section logiquement isolée du cloud AWS où vous pouvez lancer des ressources dans un réseau virtuel que vous définissez.\nAmazon VPC vous permet de contrôler vos ressources de réseau virtuel, notamment :\nla sélection d’une plage d’adresses IP la création de sous-réseaux la configuration de tables de routage et de passerelles réseau. Vous permet de personnaliser la configuration réseau de votre VPC.\nVous permet d’utiliser plusieurs couches de sécurité.\nNote Lorsque vous créez un compte AWS, un VPC “par défaut” est créé pour vous. Chaque VPC a une plage d’adresse définie. Chaque sous-réseau ou instance déployée dans le VPC aura une adresse IP incluse dans cette plage. VPC et sous-réseaux VPC :\nLogiquement isolées des autres VPC. Dédiés à votre compte AWS. Appartiennent à une seule région AWS et peuvent s’étendre sur plusieurs zones de disponibilité. Sous-réseaux :\nPlages d’adresses IP qui divient un VPC. Appartiennent à une seule zone de disponibilité. Classés comme publics ou privé Adressage IP Lorsque vous créez un VPC, vous l’affectez à un bloc d’adresse CIDR IPv4 (plage d’adresses IPv4 privées).\nUne fois que vous avez crée le VPC, nous ne pouvez plus modifier la plage d’adresses.\nLa plus grande taille de bloc d’adresse CIDR IPv4 est /16.\nLa plus petite taille de bloc d’adresse CIDR IPv4 est /28.\nIPv6 est également pris en charge.\nLes blocs d’adresses CIDR des sous-réseaux ne peuvent pas se chevaucher.\nAdresses réservées Exemple :\nUn VPC avec un bloc d’adresse CIDR IPv4 de 10.0.0.0/16 a 65 536 (2^16) adresses IP au total.\nLe VPC possède 4 sous-réseaux\n10.0.0.0/24 10.0.1.0/24 10.0.2.0/24 10.0.3.0/24 251 adresses IP sont disponibles par sous réseau (2^8 - 5 adresses réservées).\nTypes d’adresses IP publiques Adresse IP privées :\nOn attribue une adresse IP privée à ahaque machine déployée dans un sous-réseau. Cette adresse IP est inclue dans la plage d’adresses du sous-réseau. Adresse IPv4 publique :\nAttribuée manuellement via une adresse IP Elastic Attribuée automatiquement Adresse IP Elastic\nAssociée à un compte AWS Peut être allouée et remappée à tout moment Interface réseau Elastic Une interface réseau Elastic est une interface réseau virtuelle que vous pouvez :\nAttacher à une instance Détacher de l’instance et attacher à une autre instance pour rediriger le trafic réseau Ses attributs sont conservés lorsqu’elle est rattachée à une nouvelle instance.\nChaque instanbce de votre VPC possède une interface réseau par défaut à laquelle est attribuée une adresse IPv4 à partir de la plage d’adresses IPv4 de votre VPC.\nTables de routage et routes Une table de routage contient un ensemble de règles (ou routes) que vous pouvez configurer pour déterminer où le trafic réseau doit être dirigé depuis votre sous-réseau.\nChaque route spécifie une destination et une cible.\nPar défaut, chaque table de routage contient la route locale pour la communication au sein du VPC.\nChaque sous-réseau doit être associé à une table de routage (au plus une).\nNote Pensez une table de routage comme un GPS : Elle redirige les données vers la destination (adresse IP de destination). Votre VPC par défaut a déjà une table de routage principale.",
    "description": "Définitions Définition simplifiée :\nUn VPC (Virtual Private Cloud) est une sous-section privée d’AWS que vous contrôlez et dans laquelle vous pouvez placer des ressources AWS (telles que des instances EC2 et des bases de données). Vous avez un contrôle total sur l’accès aux ressources AWS que vous déployez dans votre VPC. Définition d’AWS :\nAmazon Virtual Private Cloud (VPC) permet de mettre en service une section logiquement isolée du cloud AWS où vous pouvez lancer des ressources dans un réseau virtuel que vous définissez.",
    "tags": [],
    "title": "Virtual Private Cloud",
    "uri": "/420-414/2-reseau/1-notions/1-vpc/index.html"
  },
  {
    "breadcrumb": "Réseau Infonuagique \u003e Notions",
    "content": "Passerelle Internet (Internet Gateway ou IGW) Définition simplifiée\nUne combinaison de matériel et de logiciel qui fournit à votre VPC une route vers le monde extérieur (c’est-à-dire l’Internet). Définition AWS\n“Une passerelle Internet est un composant VPC redondant et hautement disponible, mis à l’echelle horizontalement, qui permet la communication entre les instances de votre VPC et Internet. Elle n’impose donc aucun risque de disponibilité ni aucune contrainte de bande passante à votre trafic réseau. Note Votre VPC par défaut a déjà une passerelle internet attachée. On ne peut attacher qu’un IGW par VPC. Passerelle NAT Définition AWS\n“Une passerelle NAT est un service de traduction d’adresses réseau (NAT). Vous pouvez utiliser une passerelle NAT afin que les instances d’un sous-réseau privé puissent se connecter à des services en dehors de votre VPC (sur Internet), mais que les services externes ne puissent pas initier une connexion avec ces instances.”",
    "description": "Passerelle Internet (Internet Gateway ou IGW) Définition simplifiée\nUne combinaison de matériel et de logiciel qui fournit à votre VPC une route vers le monde extérieur (c’est-à-dire l’Internet). Définition AWS\n“Une passerelle Internet est un composant VPC redondant et hautement disponible, mis à l’echelle horizontalement, qui permet la communication entre les instances de votre VPC et Internet. Elle n’impose donc aucun risque de disponibilité ni aucune contrainte de bande passante à votre trafic réseau.",
    "tags": [],
    "title": "Passerelles",
    "uri": "/420-414/2-reseau/1-notions/2-passerelles/index.html"
  },
  {
    "breadcrumb": "Réseau Infonuagique \u003e Notions",
    "content": "Groupe de sécurité (Security Group ou SG) Pare-feu/couche de sécurité au niveau d’une instance (spécifiquement au niveau de l’interface/carte réseau).\nLes groupes de sécurité ont des règles qui contrôlent le trafic d’instance entrant (inbound) et sortant (outbound).\nLes groupes de sécurité par défaut refusent tout trafic entrant et autorisent tout le trafic sortant.\nLes groupes de sécurité sont avec état (stateful) : On ne définit que le trafic entrant, le trafic sortant est toujours autorisé.\nListe de contrôle d’accès réseau (Network ACLs ou NACL) Pare-feu/couche de sécurité qui contrôle le trafic entrant (inbound) et sortant (outbound) pour un ou plusieurs subnet(s) (au niveau du subnet).\nLes ACL réseau agissent au niveau du sous-réseau\nUne ACL réseau comporte des règles entrantes et sortantes distinctes.\nLes ACL réseau par défaut autorisent tout le trafic IPv4 entre et sortant.\nLes ACL réseau sont sans état (stateless) : Il n’enregistre pas les requêtes. Il faut donc définir des règles pour le trafic entrant ET sortant du sous-réseau.\nRègles de l’ACL réseau par défaut : Groupe de sécurité vs ACL réseau",
    "description": "Groupe de sécurité (Security Group ou SG) Pare-feu/couche de sécurité au niveau d’une instance (spécifiquement au niveau de l’interface/carte réseau).\nLes groupes de sécurité ont des règles qui contrôlent le trafic d’instance entrant (inbound) et sortant (outbound).\nLes groupes de sécurité par défaut refusent tout trafic entrant et autorisent tout le trafic sortant.\nLes groupes de sécurité sont avec état (stateful) : On ne définit que le trafic entrant, le trafic sortant est toujours autorisé.",
    "tags": [],
    "title": "Sécurité de VPC",
    "uri": "/420-414/2-reseau/1-notions/3-securite-vpc/index.html"
  },
  {
    "breadcrumb": "Réseau Infonuagique",
    "content": "Création d’un VPC et déploiement d’un serveur web Présentation et objectifs Dans cet atelier, vous allez utiliser Amazon Virtual Private Cloud (VPC) pour créer votre propre VPC et y ajouter des composants pour obtenir un réseau personnalisé. Ensuite, vous allez créer un groupe de sécurité, configurer et personnaliser une instance EC2 pour y exécuter un serveur web et lancer l’exécution de cette instance EC2 dans un sous-réseau du VPC.\nAmazon Virtual Private Cloud (Amazon VPC) vous permet de lancer des ressources Amazon Web Services (AWS) dans un réseau virtuel que vous définissez. Ce réseau virtuel ressemble beaucoup à un réseau classique que vous utiliseriez dans votre propre centre de données (data center), avec en plus l’avantage d’utiliser l’infrastructure d’AWS.\nÀ la fin de cet atelier, vous saurez :\nCréer un VPC ; Créer des sous-réseaux ; Configurer un groupe de sécurité ; Lancer une instance EC2 dans un VPC. Scénario Dans cet atelier, vous allez créer l’infrastructure suivante :\nÉtape 1 : Création d’un VPC Dans cette étape, vous allez utiliser la console VPC pour créer plusieurs ressources, notamment :\nUn VPC ; Une passerelle Internet (IGW) Un sous-réseau public et un sous-réseau privé dans une zone de disponibilité, Deux tables de routage Une passerelle NAT. Dans la zone de recherche à droite de Services, recherchez et choisissez VPC pour ouvrir la console VPC.\nCommencez la création d’un VPC :\nEn haut à droite de l’écran, vérifiez que la région est Virginie du Nord (us-east-1). Choisissez le lien Tableau de bord du VPC, qui se trouve également dans la partie supérieure gauche de la console. Choisissez ensuite Créer un VPC. Configurez les détails du VPC dans le volet Paramètres VPC à gauche :\nChoisissez VPC et plus encore. Sous Génération automatique d’identifications de noms, conservez l’option Génération automatique sélectionnée, mais remplacez la valeur project par lab. Conservez le bloc d’adresse CIDR IPv4 défini sur 10.0.0.0/16. Pour Nombre de zones de disponibilité, choisissez 1. Pour Nombre de sous-réseaux publics, conservez 1 Pour Nombre de sous-réseaux privés, conservez 1. Développez la section Personnaliser les blocs d’adresse CIDR des sous-réseaux. Remplacez Public subnet CIDR block in us-east-1a (Bloc d’adresse CIDR du sous-réseau public dans us-east-1a) par 10.0.0.0/24. Remplacez Private subnet CIDR block in us-east-1a (Bloc d’adresse CIDR du sous-réseau privé dans us-east-1a) par 10.0.1.0/24. Définissez Passerelles NAT sur In 1 AZ (Dans 1 AZ). Définissez Points de terminaison d’un VPC sur Aucun. Conservez les options Noms d’hôte DNS et Résolution DNS activées. Dans le volet Aperçu à droite, confirmez les paramètres que vous avez configurés :\nVPC : lab-vpc Sous-réseaux : us-east-1a Nom du sous-réseau public : lab-subnet-public1-us-east-1a Nom du sous-réseau privé : lab-subnet-private1-us-east-1a Tables de routage lab-rtb-public lab-rtb-private1-us-east-1a Connexions réseau lab-igw lab-nat-public1-us-east-1a En bas de l’écran, choisissez Créer un VPC.\nLes ressources VPC sont créées. L’activation de la passerelle NAT prend quelques minutes.\nAttendez que toutes les ressources soient créées avant de passer à l’étape suivante.\nUne fois l’opération terminée, choisissez Afficher le VPC.\nL’Assistant a mis en service un VPC avec un sous-réseau public et un sous-réseau privé dans une zone de disponibilité, avec des tables de routage pour chaque sous-réseau. Il a également créé une passerelle Internet et une passerelle NAT.\nPour afficher les paramètres de ces ressources, parcourez les liens de la console VPC qui affichent les détails des ressources. Par exemple, choisissez Sous-réseaux pour afficher les détails des sous-réseaux et choisissez Tables de routage pour afficher les détails des tables de routage. Le diagramme ci-dessous résume les ressources VPC que vous venez de créer et leur configuration :\nRappels et résumé Une passerelle Internet (IGW) est une ressource VPC qui autorise la communication entre les instances EC2 de votre VPC et Internet. Le sous-réseau public lab-subnet-public1-us-east-1a possède le bloc d’adresses CIDR 10.0.0.0/24, ce qui signifie qu’il contient toutes les adresses IP commençant par 10.0.0.x. Ce sous-réseau est public car la table de routage qui lui est associée achemine le trafic réseau 0.0.0.0/0 vers la passerelle Internet. Une passerelle NAT est une ressource VPC utilisée pour fournir une connectivité Internet aux instances EC2 exécutées dans les sous-réseaux privés du VPC sans que ces instances EC2 aient besoin d’une connexion directe à la passerelle Internet. Le sous-réseau privé lab-subnet-private1-us-east-1a possède le bloc d’adresses CIDR 10.0.1.0/24, ce qui signifie qu’il contient toutes les adresses IP commençant par 10.0.1.x. Étape 2 : Création de sous-réseaux supplémentaires Dans cette étape, vous allez créer deux sous-réseaux supplémentaires pour le VPC dans une deuxième zone de disponibilité. Il est utile d’avoir des sous-réseaux dans plusieurs zones de disponibilité d’un VPC pour déployer des solutions qui fournissent une haute disponibilité.\nDans l’étape précédente, vous avez crée un VPC, mais vous pouvez encore le configurer davantage, par exemple en ajoutant des sous-réseaux supplémentaires.\nDans le volet de navigation gauche, sélectionnez Sous-réseaux.\nTout d’abord, vous allez créer un deuxième sous-réseau public.\nChoisissez Créer un sous-réseau, puis configurez les éléments suivants :\nID de VPC : lab-vpc (sélectionnez-le dans le menu). Nom du sous-réseau : lab-subnet-public2 Zone de disponibilité : Sélectionnez une zone de disponibilité différente de la première (par exemple, us-east-1b). IPv4 CIDR block (Bloc d’adresse CIDR IPv4) : 10.0.2.0/24 Toutes les adresses IP du sous-réseau commenceront par 10.0.2.x.\nSélectionnez Créer un sous-réseau\nLe deuxième sous-réseau public a été créé. Vous allez maintenant créer un deuxième sous-réseau privé.\nChoisissez Créer un sous-réseau, puis configurez les éléments suivants :\nID de VPC : lab-vpc Nom du sous-réseau : lab-subnet-private2 Zone de disponibilité : sélectionnez la même zone de disponibilité que dans 2. (par exemple us-east-1b). IPv4 CIDR block (Bloc d’adresse CIDR IPv4) : 10.0.3.0/24 Toutes les adresses IP du sous-réseau commenceront par 10.0.3.x.\nSélectionnez Créer un sous-réseau\nLe deuxième sous-réseau privé a été créé.\nVous allez maintenant configurer ce nouveau sous-réseau privé pour router le trafic lié à Internet vers la passerelle NAT, afin que les ressources du deuxième sous-réseau privé puissent se connecter à Internet, tout en conservant les ressources privées. Pour ce faire, vous devez configurer une table de routage.\nUne table de routage contient un ensemble de règles, appelées acheminements, qui permettent de déterminer la direction du trafic réseau. Chaque sous-réseau d’un VPC doit être associé à une table de routage. Cette table de routage contrôle le routage pour le sous-réseau.\nDans le volet de navigation gauche, sélectionnez Tables de routage.\nSélectionnez la table de routage lab-rtb-private1-us-east-1a.\nDans le volet inférieur, choisissez l’onglet Routes.\nNotez que l’option Destination 0.0.0.0/0 est configurée sur Cible nat-xxxxxxxx. Cela signifie que le trafic destiné à Internet (0.0.0.0/0) sera envoyé à la passerelle NAT. La passerelle NAT transférera ensuite le trafic vers Internet.\nCette table de routage est donc utilisée pour acheminer le trafic à partir de sous-réseaux privés.\nSélectionnez l’onglet Associations de sous-réseau.\nVous avez créé cette table de routage dans l’étape 1 lorsque vous avez choisi de créer un VPC et plusieurs ressources dans ce VPC. Cette action a également créé lab-subnet-private-1 et associé ce sous-réseau à cette table de routage.\nMaintenant que vous avez créé un autre sous-réseau privé, lab-subnet-private-2, vous allez également lui associer cette table de routage.\nDans le volet Associations de sous-réseau explicites, choisissez Modifier les associations de sous-réseau.\nLaissez lab-subnet-private1-us-east-1a sélectionné, mais sélectionnez également lab-subnet-private2.\nSélectionnez Enregistrer les associations.\nVous allez maintenant configurer la table de routage utilisée par les sous-réseaux publics.\nSélectionnez la table de routage lab-rtb-public (et désélectionnez tout autre sous-réseau).\nDans le volet inférieur, choisissez l’onglet Routes.\nNotez que l’option Destination 0.0.0.0/0 est configurée sur Cible igw-xxxxxxxx, qui est une passerelle Internet. Cela signifie que le trafic lié à Internet sera envoyé à Internet via cette passerelle Internet.\nVous allez maintenant associer cette table de routage au deuxième sous-réseau public que vous avez créé.\nSélectionnez l’onglet Associations de sous-réseau.\nDans la zone Associations de sous-réseau explicites, choisissez Modifier les associations de sous-réseau.\nLaissez lab-subnet-public1-us-east-1a sélectionné, mais sélectionnez également lab-subnet-public2.\nSélectionnez Enregistrer les associations.\nVotre VPC dispose désormais de sous-réseaux publics et privés configurés dans deux zones de disponibilité. Les tables de routage que vous avez créées dans l’étape 1 ont également été mises à jour pour router le trafic réseau pour les deux nouveaux sous-réseaux.\nÉtape 3 : Création d’un groupe de sécurité Dans cette étape, vous allez créer un groupe de sécurité qui agit comme un pare-feu virtuel. Lorsque vous démarrez une instance (VM), vous lui associez un ou plusieurs groupes de sécurité. Vous pouvez ajouter des règles à chaque groupe de sécurité pour autoriser le trafic vers ou depuis ses instances associées.\nDans le volet de navigation gauche, sélectionnez Groupes de sécurité.\nChoisissez Créer un groupe de sécurité, puis configurez les paramètres suivants :\nNom du groupe de sécurité : Web Security Group Description : Enable HTTP access VPC : choisissez le symbole X pour supprimer le VPC actuellement sélectionné, puis choisissez lab-vpc dans la liste déroulante. Dans le volet Règles entrantes, choisissez Ajouter une règle.\nConfigurez les paramètres suivants :\nType : HTTP Source : Anywhere-Ipv4 Description : Permit Web Requests Faites défiler l’affichage jusqu’au bas de la page, puis choisissez Créer un groupe de sécurité.\nVous utiliserez ce groupe de sécurité dans le cadre de la prochaine étape, lors du lancement d’une instance Amazon EC2.\nÉtape 4 : Déploiement un serveur web Dans cette étape, vous allez lancer une instance Amazon EC2 dans le VPC configuré dans les étapes précédentes. Vous allez configurer l’instance pour qu’elle fonctionne en tant que serveur web.\nDans la zone de recherche, à droite de Services, recherchez et choisissez EC2 pour ouvrir la console EC2.\nDans le menu Lancer une instance, choisissez Lancer l’instance.\nNommez l’instance :\nAttribuez-lui le nom Web Server 1.\nLorsque vous nommez l’instance, AWS crée une identification et l’associe à l’instance. Une identification est une paire clé-valeur. La clé de cette paire est Nom et la valeur est le nom que vous saisissez pour votre instance EC2.\nChoisissez une AMI à partir de laquelle créer l’instance :\nDans la liste des AMI Quick Start disponibles, conservez la sélection par défaut d’Amazon Linux. Conservez également la sélection par défaut de l’AMI Amazon Linux 2023. Le type d’Amazon Machine Image (AMI) que vous choisissez détermine le système d’exploitation qui sera exécuté sur l’instance EC2 que vous lancez.\nChoisissez un type d’instance :\nDans le volet Type d’instance, conservez la valeur par défaut t2.micro sélectionnée.\nL’option Type d’instance définit les ressources matérielles affectées à l’instance.\nSélectionnez la paire de clés à associer à l’instance :\nDans le menu Nom de la paire de clés, sélectionnez vockey. La paire de clés vockey que vous avez sélectionnée vous permettra de vous connecter à cette instance via SSH après son lancement. Bien qu’il ne soit pas nécessaire d’exécuter cette opération dans ce laboratoire, vous devez toujours identifier une paire de clés existante, en créer une nouvelle ou choisir de continuer sans paire de clés lors du lancement d’une instance.\nConfigurez les paramètres réseau :\nDans la section Paramètres réseau, choisissez Modifier, puis configurez :\nRéseau : lab-vpc Sous-réseau : lab-subnet-public2 (non privé !) Attribuer automatiquement l’adresse IP publique : Activer Vous allez ensuite configurer l’instance de manière à utiliser le Groupe de sécurité web que vous avez créé précédemment.\nSous Pare-feu (groupes de sécurité), choisissez Sélectionner un groupe de sécurité existant.\nPour Groupes de sécurité courants, sélectionnez Groupe de sécurité web.\nCe groupe de sécurité permettra un accès HTTP à l’instance.\nDans la section Configurer le stockage, conservez les paramètres par défaut.\nRemarque : les paramètres par défaut indiquent que le volume racine de l’instance, qui hébergera le système d’exploitation invité Amazon Linux que vous avez spécifié précédemment, s’exécutera sur un disque dur SSD polyvalent (gp3) de 8 Gio. Vous pouvez également ajouter des volumes de stockage supplémentaires, mais cela n’est pas nécessaire dans cet atelier.\nConfigurez un script pour qu’il s’exécute sur l’instance à son lancement :\nDéveloppez le volet Détails avancés. Faites défiler la page jusqu’en bas, puis copiez et collez le code ci-dessous dans la zone Données utilisateur : #!/bin/bash # Install Apache Web Server and PHP dnf install -y httpd wget php mariadb105-server # Download Lab files wget https://aws-tc-largeobjects.s3.us-west-2.amazonaws.com/CUR-TF-100-ACCLFO-2/2-lab2-vpc/s3/lab-app.zip unzip lab-app.zip -d /var/www/html/ # Turn on web server chkconfig httpd on service httpd start Ce script s’exécutera avec des autorisations d’administrateur sur le système d’exploitation de l’instance. Il sera exécuté automatiquement lorsque l’instance sera lancée pour la première fois. Le script installe un serveur web, une base de données et des bibliothèques PHP, puis télécharge et installe une application web PHP sur le serveur web.\nEn bas du volet Résumé, à droite de l’écran, choisissez Lancer l’instance.\nUn message de réussite s’affiche.\nSélectionnez Afficher toutes les instances.\nAttendez que Web Server 1 affiche 2/2 checks passed (2/2 contrôles réussis) dans la colonne Contrôles des statuts.\nVous allez maintenant vous connecter au serveur web s’exécutant sur l’instance EC2.\nSélectionnez Web Server 1.\nCopiez la valeur de Public IPv4 DNS (DNS IPv4 public) indiquée dans l’onglet Détails au bas de la page.\nOuvrez un nouvel onglet de navigateur web, collez la valeur DNS public et appuyez sur Entrée.\nVous devriez alors voir une page web afficher le logo AWS et les valeurs de métadonnées d’instance.\nFélicitation, vous venez de déployer votre première infrastructure réseau et votre premier serveur Web sur le Cloud ! L’architecture complète que vous avez déployée est la suivante :\nConseils Pour vous assurer de maitriser les méthodes vues dans ce laboratoire, n’hésitez pas à le refaire sans l’aide de ce guide (la meilleure façon d’apprendre, c’est de répéter de façon autonome).",
    "description": "Création d’un VPC et déploiement d’un serveur web Présentation et objectifs Dans cet atelier, vous allez utiliser Amazon Virtual Private Cloud (VPC) pour créer votre propre VPC et y ajouter des composants pour obtenir un réseau personnalisé. Ensuite, vous allez créer un groupe de sécurité, configurer et personnaliser une instance EC2 pour y exécuter un serveur web et lancer l’exécution de cette instance EC2 dans un sous-réseau du VPC.\nAmazon Virtual Private Cloud (Amazon VPC) vous permet de lancer des ressources Amazon Web Services (AWS) dans un réseau virtuel que vous définissez.",
    "tags": [],
    "title": "Laboratoire",
    "uri": "/420-414/2-reseau/2-laboratoire/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Au cours des deux dernières décennies, la manière dont les entreprises gèrent leur infrastructure a beaucoup évolué. L’époque des serveurs physiques dédiés est révolue depuis longtemps, et il existe toute une série d’options pour tirer le meilleur parti de vos hôtes et services, que vous les déployez sur-site ou dans le nuage.\nLa virtualisation a ouvert la voie à la scalabilité, à la normalisation et à l’optimisation des coûts.\nLa conteneurisation a apporté de nouvelles efficacités.\nDans ce module, nous aborderons les spécificité de chacun des deux, plus spécifiquement :\nLa virtualisation : types, spécificités, avantages et inconvénients\nLa conteneurisation : types, spécificités, avantages et inconvénients\nDéploiement de machines virtuelles sur le Cloud AWS (EC2)\nIntroduction à Docker : +",
    "description": "Au cours des deux dernières décennies, la manière dont les entreprises gèrent leur infrastructure a beaucoup évolué. L’époque des serveurs physiques dédiés est révolue depuis longtemps, et il existe toute une série d’options pour tirer le meilleur parti de vos hôtes et services, que vous les déployez sur-site ou dans le nuage.\nLa virtualisation a ouvert la voie à la scalabilité, à la normalisation et à l’optimisation des coûts.\nLa conteneurisation a apporté de nouvelles efficacités.",
    "tags": [],
    "title": "VM/Conteneur",
    "uri": "/420-414/3-vm-conteneur/index.html"
  },
  {
    "breadcrumb": "VM/Conteneur",
    "content": "Autrefois, les serveurs physiques fonctionnaient comme un ordinateur ordinaire. Vous disposiez d’un boîtier physique, vous installiez un système d’exploitation, puis vous installiez des applications par-dessus.\nCes types de serveurs sont appelés “serveurs bare-metal” (n’y a rien entre la machine physique et le système d’exploitation).\nCes serveurs étaient dédiés à un usage spécifique. La gestion était simple et les problèmes plus faciles à traiter mais les coûts étaient élevés : Il fallait de plus en plus de serveurs au fur et à mesure qu’une entreprise se développait.\nLa virtualisation existe depuis les années 1960, mais a commencé se développer au début des années 2000. Plutôt que de faire fonctionner le système d’exploitation directement sur le matériel physique, une couche de virtualisation supplémentaire est ajoutée entre les deux, ce qui permet de déployer plusieurs serveurs virtuels, chacun avec son propre système d’exploitation, le tout sur une seule machine physique.\nCela permet de réaliser des économies et une optimisation des ressources matérielles considérables, et a finalement conduit à l’existence du cloud computing.\nLe rôle d’un hyperviseur La virtualisation ne serait pas possible sans hyperviseurs - une couche logicielle qui permet à plusieurs machines virtuelles/systèmes d’exploitation de coexister tout en partageant les ressources d’un seul hôte matériel. L’hyperviseur sert d’intermédiaire entre les machines virtuelles et le matériel sous-jacent, en allouant les ressources de l’hôte telles que la mémoire, le processeur et le stockage à chacune des VMs.\nTypes d’hyperviseurs Il existe deux principaux types d’hyperviseurs :\nHyperviseurs de type 1 ou “bare-metal” : Ils s’exécutent directement sur le matériel de l’hôte et sont responsables de la gestion des ressources matérielles et de l’exécution des machines virtuelles. Comme ils s’exécutent directement sur le matériel, ils sont souvent plus efficaces que les hyperviseurs de type 2.\nExemples : VMware ESXi, Microsoft Hyper-V, Proxmox etc… Hyperviseurs de type 2 ou hébergés : Ils s’exécutent au-dessus d’un système d’exploitation hôte et s’appuient sur celui-ci pour fournir les ressources matérielles nécessaires. Comme ils s’exécutent au-dessus d’un système d’exploitation, ils sont souvent plus faciles à installer et à utiliser que les hyperviseurs de type 1, mais sont en général moins efficaces.\nExemples : VMware Workstation, Oracle VirtualBox etc… Avantages Réduction des coûts : En faisant tourner plusieurs machines virtuelles sur un seul serveur physique, on économise de l’argent et de l’espace. Meilleure utilisation des ressources et plus grande flexibilité : La possibilité d’exécuter plusieurs machines virtuelles sur un seul serveur permet d’éviter de gaspiller les capacités matérielles des serveurs. Facilite l’évolution, la gestion des ressources et les plans de reprise après une catastrophe : Il est possible de créer, détruire et migrer facilement des machines virtuelles entre hôtes. Inconvénients Peut créer une surcharge des performances : Introduit une couche supplémentaire entre l’hôte et le système d’exploitation. Ajoute un niveau de complexité : Il faut gérer et entretenir des instances physiques ET virtuelles.",
    "description": "Autrefois, les serveurs physiques fonctionnaient comme un ordinateur ordinaire. Vous disposiez d’un boîtier physique, vous installiez un système d’exploitation, puis vous installiez des applications par-dessus.\nCes types de serveurs sont appelés “serveurs bare-metal” (n’y a rien entre la machine physique et le système d’exploitation).\nCes serveurs étaient dédiés à un usage spécifique. La gestion était simple et les problèmes plus faciles à traiter mais les coûts étaient élevés : Il fallait de plus en plus de serveurs au fur et à mesure qu’une entreprise se développait.",
    "tags": [],
    "title": "Virtualisation",
    "uri": "/420-414/3-vm-conteneur/1-virtualisation/index.html"
  },
  {
    "breadcrumb": "VM/Conteneur",
    "content": "Comme la virtualisation, la conteneurisation permet aussi d’exécuter de nombreuses instances sur un seul hôte physique, mais sans que l’hyperviseur ne joue le rôle d’intermédiaire.\nAu lieu de cela, la fonctionnalité du noyau du système hôte est utilisée pour isoler plusieurs instances indépendantes appelées conteneurs.\nEn partageant le noyau et le système d’exploitation de l’hôte, les conteneurs évitent le gaspillage de ressources matérielles de la virtualisation (il n’est pas nécessaire de fournir un noyau et un système d’exploitation virtuels différents pour chaque instance). C’est pourquoi les conteneurs sont considérés comme une solution plus légère - ils nécessitent moins de ressources sans compromettre les performances.\nTypes de conteneurs Il existe deux principaux types de conteneurs :\nConteneurs d’application (Docker) : Empaquettent et exécutent un “processus” (ou service) unique par conteneur. Ils sont emballés (ou conteneurisé) avec toutes les bibliothèques, dépendances et fichiers de configuration dont ils ont besoin pour fonctionner, ce qui facilite leur portabilité dans différents environnements. Conteneurs système (LXC) : Similaires à une machine virtuelle. Ils exécutent un système d’exploitation complet et ont le même comportement et la même facilité de gestion que les machines virtuelles tout en étant plus légers, avec en plus les avantages de densité et d’efficacité qu’offrent les conteneurs. Avantages Densité : Il est possible de faire fonctionner plusieurs conteneurs tout en bénéficiant des performances d’un système “bare-metal”. Efficacité : Permettent de déployer des applications beaucoup plus rapidement que des VMs. Portabilité : Toutes les dépendances sont déjà intégrées dans le conteneur. Inconvénients L’exécution de plusieurs conteneurs peut augmenter la complexité de l’environnement. Augmente la difficulté de surveillance et d’observabilité (dans un environnement avec des milliers de conteneurs). Toute vulnérabilité du noyau de l’hôte compromet tout ce qui s’exécute dans les conteneurs.",
    "description": "Comme la virtualisation, la conteneurisation permet aussi d’exécuter de nombreuses instances sur un seul hôte physique, mais sans que l’hyperviseur ne joue le rôle d’intermédiaire.\nAu lieu de cela, la fonctionnalité du noyau du système hôte est utilisée pour isoler plusieurs instances indépendantes appelées conteneurs.\nEn partageant le noyau et le système d’exploitation de l’hôte, les conteneurs évitent le gaspillage de ressources matérielles de la virtualisation (il n’est pas nécessaire de fournir un noyau et un système d’exploitation virtuels différents pour chaque instance).",
    "tags": [],
    "title": "Conteneurisation",
    "uri": "/420-414/3-vm-conteneur/2-conteneurisation/index.html"
  },
  {
    "breadcrumb": "VM/Conteneur",
    "content": "Amazon Elastic Compute Cloud (Amazon EC2) est un service AWS qui permet de créer et gérer des machines virtuelles (appelées instances EC2) dans le cloud AWS.\nCréation d’une VM EC2 Les points les plus importants à configurer lorsque vous voulez lancer une instance EC2 :\nAMI Type d’instance Paramètres réseau Données utilisateur Options de stockage Groupe de sécurité Paire de clés AMI Amazon Machine Image (AMI) est un modèle (ou image) utilisé.e pour créer une instance EC2 Contient un système d’exploitation Windows ou Linux Certains logiciels sont souvent préinstallés Il est aussi possible de créer une AMI pour ensuite l’utiliser comme template. (comme un .ova ou un snapshot) Type d’instance Le type d’instance que vous choisissez dépend de vos besoins en :\nMémoire RAM Puissance de traitement (CPU) Espace disque et type de disque (stockage) Performances réseau Dénomination des types d’instances Exemple : t3.large\nt correspond au nom de la famille 3 correspond au numéro de génération large correspond à la taille Paramètres réseau Pour lancer une instance EC2, il faut spécifier le VPC et le sous-réseau où elle sera déployée. L’instance doit-elle avoir une adresse IP publique (pour la rendre accessible sur Internet) ? Si oui, il faut aussi le spécifier lors de la création. Données utilisateur (user-data) Vous pouvez (optionnellement) spécifier un script de données utilisateur (user data) au lancement de l’instance Le script s’exécute au démarrage initial de l’instance (avec les privilèges root) Options de stockage Il est nécessaire de configurer le volume racine (emplacement d’installation du système d’exploitation) Il est possible d’attachez des volumes de stockage supplémentaires (facultatif) Pour chaque volume, il est possible indiquez la taille du disque (en Go), le type de volume (SSD, HDD), si le volume doit être supprimé lorsque l’instance est détruite, si vous souhaitez chiffrer le volume Groupe de sécurité Rappel : Un groupe de sécurité est un ensemble de règles de pare-feu qui contrôlent le trafic entrant de l’instance. Paire de clés Au lancement de l’instance, vous devez indiquer une paire de clés existante ou en créer une Une paire de clés comprend : Une clé publique stockée par AWS Un fichier de clé privée que vous stockez Elle permet de sécuriser les connexions à une instance (via SSH pour les instances Linux, RDP pour les instances Windows) Interface de ligne de commande (CLI) Les instances EC2 (ainsi que d’autres services AWS) peuvent également être crées par programmation. Exemple de commande (suppose que la paire de clé et le groupe de sécurité existent déjà) :\naws ec2 run-instances / --image-id ami-1a2b3c4d / --count 1 / --instance-type c3.large / --key-name MyKeyPair / --security-groups MySecurityGroup --region us-east-1 Cycle de vie Le redémarrage d’une instance ne modifie aucune adresse IP ni aucun nom de domaine Lorsqu’une instance est arrêtée puis redémarrée : L’adresse IPv4 publique et le nom de domaine externe changent. L’adresse IPv4 privée et le nom de domaine interne ne change pas. Métadonnées Les métadonnées d’une instance sont des données relatives à une instance Vous pouvez les visualiser lorsque vous êtes connecté à l’instance : Dans un navigateur : http://169.254.169.254/latest/meta-data/ Dans un terminal : curl http://169.254.169.254/latest/meta-data/ Exemples de données : Adresse IP publique, privée, nom de domaine public, ID de l’instance, groupes de sécurité, région, zone de disponibilité. Les données utilisateur sont aussi accessibles : http://169.254.169.254/latest/user-data",
    "description": "Amazon Elastic Compute Cloud (Amazon EC2) est un service AWS qui permet de créer et gérer des machines virtuelles (appelées instances EC2) dans le cloud AWS.\nCréation d’une VM EC2 Les points les plus importants à configurer lorsque vous voulez lancer une instance EC2 :\nAMI Type d’instance Paramètres réseau Données utilisateur Options de stockage Groupe de sécurité Paire de clés AMI Amazon Machine Image (AMI) est un modèle (ou image) utilisé.",
    "tags": [],
    "title": "Amazon EC2",
    "uri": "/420-414/3-vm-conteneur/3-ec2/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/420-414/categories/index.html"
  },
  {
    "breadcrumb": "",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/420-414/tags/index.html"
  }
]
